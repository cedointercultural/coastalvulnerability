#' PCA of indicators
#'
#' @param thisdata
#' @param indicator.name
#'
#' @return
#' @export
#'
#' @examples
#' @author Hem Nalini Morzaria-Luna, hmorzarialuna@gmail.com
pca_factor <- function(this.data, indicator.name){

  var <- dplyr::sym(paste0("tot_", indicator.name))

  mun.data <- unique(this.data$CVE_MUN)

  items.scale <- ncol(loc.data)

  mun.scores <- list()

  ind.category <- unique(this.data$indicator_category)

  for(eachcategory in 1:length(ind.category)){

    this.category <- ind.category[eachcategory]

    this.data.cat <- this.data %>%
      keep_when(indicator_category==thiscategory)

  for(eachmun in 1:length(mun.data)){

    this.mun <- mun.data[eachmun]

    mun.loc.data <- this.data %>%
      keep_when(CVE_MUN==this.mun)

    loc.index <- mun.loc.data %>%
      select(CVE_MUN, CVE_LOC, indicator)

      #eliminate id columns, needs only data values

    loc.data <- mun.loc.data %>%
      select(-CVE_MUN, -CVE_LOC)

    #run single factor solution
    model1.impact<- psych::principal(loc.data, nfactors = 1, rotate = "none",scores=TRUE) #can specify rotate="varimax"
    model1.impact

    factorscores.impact <- model1.impact$scores %>%
      tidyr::as_tibble() %>%
      dplyr::bind_cols(loc.index) %>%
      dplyr::mutate_if(is.numeric,~ scales::rescale(., to = c(0, 1)))

    readr::write_csv(factorscores.impact,here::here("outputs","analysis",paste0("factor_scores_",indicator.name,".csv")))


  }

}




  # items.scale <- ncol(loc.data)
  #
  # #obtain correlation matrix
  # hozdatamatrix.impact <- cor(loc.data, use="pairwise")
  # #print correlation plot
  # #pairs(loc.data)
  #
  # # print out the correlation matrix but ask for numbers to 3 decimal places
  # corrmat.impact  <- round(hozdatamatrix.impact,3)
  # corrmat.impact
  # # bartlett test - want a small p value here to indicate c0rrelation matrix not zeros
  # psych::cortest.bartlett(loc.data)
  #
  # #principal components analysis
  #
  # # Determine Number of Factors to Extract
  #
  # #This code can be use to determine the optimal number of factors, however Jacob et al (2012)
  # #recommends using a single factor solution
  # # Generally, if the goal is simple and parsimonious description of a correlation
  # # or covariance matrix, the first k principal components
  # # will do a better job than any other k-dimensional solution
  # try(ev <- eigen(hozdatamatrix.impact)) # get eigenvalues
  # try(ap <- nFactors::parallel(subject=nrow(loc.data),var=ncol(loc.data),
  #                rep=100,cent=.05))
  # try(nS <- nFactors::nScree(ev$values, ap$eigen$qevpea))
  # #nFactors::plotnScree(nS)
  #
  #
  #
  # #run single factor solution
  # model1.impact<- psych::principal(loc.data, nfactors = 1, rotate = "none",scores=TRUE) #can specify rotate="varimax"
  # model1.impact
  # #SS loading is the eigenvalue
  # # h2is called the communality estimate. Measures the % of variance
  # # in an observed variable accounted for by the retained components
  #
  # # prcomp library factoextra
  # #plot variables that continue most to the PCA
  # # res.pca <- prcomp(loc.data, scale = TRUE)
  # #
  # # factoextra::fviz_pca_var(res.pca,
  # #              col.var = "contrib", # Color by contributions to the PC
  # #              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
  # #              repel = TRUE     # Avoid text overlapping
  # # )
  # #
  # # variable.plot <-  factoextra::fviz_cos2(res.pca, choice="var", axes = 1 )
  # #
  # # ggsave(here("outputs","figures",paste0("variables_pca_",indicator.name,".png")), variable.plot, device="png", width = 8, height = 5)
  #
  #
  # # can find the reproduced correlations and the communalities (the diagonals)
  # # factor.model(model1.impact$loadings)
  # #
  # # model.loadings <- unclass(model1.impact$loadings) %>%
  # #   as_tibble(rownames="var") %>%
  # #   dplyr::rename(loadings = PC1) %>%
  # #   mutate(data_name = indicator.name)
  # #
  # # write_csv(model.loadings,here("outputs","analysis",paste0("model_loadings_",indicator.name,".csv")))
  # #
  # #
  # # # the diagonals represent the uniqueness values (1- R squared):
  # # residuals.impact <- factor.residuals(hozdatamatrix.impact, model1.impact$loadings)
  # # residuals.impact
  # # # nice to plot the residuals to check there are normally distributed
  # # #hist(residuals.impact)
  #
  # # to save the above values we need to add them to a dataframe
  # factorscores.impact <- model1.impact$scores %>%
  #   tidyr::as_tibble(rownames="LOC")
  #
  # readr::write_csv(factorscores.impact,here::here("outputs","analysis",paste0("factor_scores_",indicator.name,".csv")))
  #
  # #obtain largest eigenvalue
  # larg.eigen  <- max(model1.impact$values)
  # #Armor's Theta tests for internal consistency of a factor scale
  # Theta  <- (items.scale/(items.scale-1)) * (1-(1/larg.eigen))
  #
  # #shows the summary of the loadings table
  #
  # p <- print(model1.impact)
  #
  # model.summary <-  round(p$Vaccounted,2)  %>%
  #   tidyr::as_tibble(rownames = "Var") %>%
  #   dplyr::bind_rows(tidyr::tibble(Var = c("Eigenvalue","Theta"),PC1=c(larg.eigen, Theta))) %>%
  #   keep_when(Var!="SS loadings")
  #
  # readr::write_csv(model.summary,here::here("outputs","analysis",paste0("model_summary_",indicator.name,".csv")))

}
